{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a2c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.approx_layers.systolic_utils import compare_exact_vs_approx#, testlinear,check_equal\n",
    "#check_equal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a115dd",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with AdaPT on Cifar10 dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models based on Cifar10 dataset\n",
    "\n",
    "Steps:\n",
    "* Select models to load \n",
    "* Select number of threads to use\n",
    "* Choose approximate multiplier \n",
    "* Load model for evaluation\n",
    "* Load dataset\n",
    "* Run model calibration for quantization\n",
    "* Run model evaluation\n",
    "* Run approximate-aware re-training\n",
    "* Rerun model evaluation\n",
    "\n",
    "**Note**:\n",
    "* This notebook should be run on a X86 machine\n",
    "\n",
    "* Please make sure you have run the installation steps first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5eef0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab49b35",
   "metadata": {},
   "source": [
    "## Select models to load \n",
    "\n",
    "The weights must be downloaded in state_dicts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "#from models.resnet_systolic import resnet50_systolic\n",
    "from models.vgg import vgg11_bn, vgg13_bn, vgg19_bn\n",
    "from models.densenet import densenet121, densenet161, densenet169\n",
    "from models.inception import inception_v3 # slow, propably bad cifar10 implementation of inception for PT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69265983",
   "metadata": {},
   "source": [
    "## Select number of threads to use\n",
    "\n",
    "For optimal performance set them as the number of your cpu threads (not cpu cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165c2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_PLACES=cores\n",
      "env: OMP_PROC_BIND=close\n",
      "env: OMP_WAIT_POLICY=active\n"
     ]
    }
   ],
   "source": [
    "threads = 40\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "#maybe better performance\n",
    "%env OMP_PLACES=cores\n",
    "%env OMP_PROC_BIND=close\n",
    "%env OMP_WAIT_POLICY=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06300",
   "metadata": {},
   "source": [
    "## Choose approximate multiplier \n",
    "\n",
    "Two approximate multipliers are already provided\n",
    "\n",
    "**mul8s_acc** - (header file: mul8s_acc.h)   <--  default\n",
    "\n",
    "**mul8s_1L2H** - (header file: mul8s_1L2H.h)\n",
    "\n",
    "\n",
    "\n",
    "In order to use your custom multiplier you need to use the provided tool (LUT_generator) to easily create the C++ header for your multiplier. Then you just place it inside the adapt/cpu-kernels/axx_mults folder. The name of the axx_mult here must match the name of the header file. The same axx_mult is used in all layers. \n",
    "\n",
    "Tip: If you want explicitly to set for each layer a different axx_mult you must do it from the model definition using the respective AdaPT_Conv2d class of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562689c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "axx_mult = 'mul8s_acc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e7e1",
   "metadata": {},
   "source": [
    "## Load model for evaluation\n",
    "\n",
    "Jit compilation method loads 'on the fly' the C++ extentions of the approximate multipliers. Then the pytorch model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc26796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_acc/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_acc...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): AdaPT_Conv2d(\n",
       "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(pretrained=True, axx_mult = axx_mult)\n",
    "\n",
    "model.eval() # for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721ed0",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63b4701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def val_dataloader(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)):\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = CIFAR10(root=\"datasets/cifar10_data\", train=False, download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "transform = T.Compose(\n",
    "        [\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    )\n",
    "dataset = CIFAR10(root=\"datasets/cifar10_data\", train=True, download=True, transform=transform)\n",
    "\n",
    "evens = list(range(0, len(dataset), 10))\n",
    "trainset_1 = torch.utils.data.Subset(dataset, evens)\n",
    "\n",
    "data = val_dataloader()\n",
    "\n",
    "# data_t is used for calibration purposes and is a subset of train-set\n",
    "data_t = DataLoader(trainset_1, batch_size=128,\n",
    "                                            shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa74c5d",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "946f0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                 module.load_calib_amax(**kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "#with torch.no_grad():\n",
    "#    stats = collect_stats(model, data_t, num_batches=2)\n",
    "#    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446f0bd",
   "metadata": {},
   "source": [
    "## Run model evaluation\n",
    "\n",
    "Tip: observe how the execution becomes faster and faster with each batch as the CPU achieves better cache re-use on the LUT table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44bfa498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "#correct = 0\n",
    "#total = 0\n",
    "\n",
    "#model.eval()\n",
    "#start_time = timeit.default_timer()\n",
    "#with torch.no_grad():\n",
    "#    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "#        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "#        outputs = model(images)\n",
    "#        _, predicted = torch.max(outputs.data, 1)\n",
    "#        total += labels.size(0)\n",
    "#        correct += (predicted == labels).sum().item()\n",
    "#print(timeit.default_timer() - start_time)\n",
    "#print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "#    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204303c",
   "metadata": {},
   "source": [
    "## Run approximate-aware re-training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f33540ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.references.classification.train import evaluate, train_one_epoch, load_data\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# finetune the model for one epoch based on data_t subset \n",
    "#train_one_epoch(model, criterion, optimizer, data_t, \"cpu\", 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e03900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): AdaPT_Conv2d(\n",
       "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "save_path = \"aa_finetuned_model.pth\"\n",
    "\n",
    "# Load the state dict\n",
    "state_dict = torch.load(save_path, map_location=\"cpu\")\n",
    "\n",
    "# Apply it\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83c69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_cpu = model.to(\"cpu\").eval()\n",
    "\n",
    "# Strip quantizer buffers before saving\n",
    "cpu_sd = {k: v for k, v in model_cpu.state_dict().items()\n",
    "          if not k.endswith(\"._amax\") and k.split(\".\")[-1] not in\n",
    "          {\"_amax\", \"_amax_hist\", \"_amax_threshold\", \"_observed_amax\", \"_calibrator\"}}\n",
    "\n",
    "torch.save(cpu_sd, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0bfa0",
   "metadata": {},
   "source": [
    "## Rerun model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "#model = resnet50(pretrained=False, axx_mult=axx_mult)\n",
    "#model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "#with torch.no_grad():\n",
    "#    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "#        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "#        outputs = model(images)\n",
    "#        _, predicted = torch.max(outputs.data, 1)\n",
    "#        total += labels.size(0)\n",
    "#        correct += (predicted == labels).sum().item()\n",
    "#print(timeit.default_timer() - start_time)\n",
    "#print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "#    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb49aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# force TensorQuantizers to load buffers on CPU instead of .cuda()\n",
    "def force_quantizer_cpu():\n",
    "    import torch\n",
    "    from pytorch_quantization.nn import modules\n",
    "\n",
    "    orig_fn = modules.tensor_quantizer.TensorQuantizer._load_from_state_dict\n",
    "\n",
    "    def new_fn(self, state_dict, prefix, *args, **kwargs):\n",
    "        key = prefix + '_amax'\n",
    "        if key in state_dict:\n",
    "            buf = state_dict[key].data.cpu()   # force CPU\n",
    "            self.register_buffer(\"_amax\", buf)\n",
    "        else:\n",
    "            # fallback to original\n",
    "            orig_fn(self, state_dict, prefix, *args, **kwargs)\n",
    "\n",
    "    modules.tensor_quantizer.TensorQuantizer._load_from_state_dict = new_fn\n",
    "\n",
    "force_quantizer_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72fe1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#from torchvision.models import resnet50\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "from torchvision import transforms\n",
    "from adapt.approx_layers.systolic_utils import compare_exact_vs_approx\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2470, 0.2435, 0.2616)),   # CIFAR-10 stats (example)\n",
    "])\n",
    "\n",
    "test_dataset = CIFAR10(root=\"datasets/cifar10_data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# IMPORTANT: num_workers=0 to avoid OpenMP + fork segfaults with C++ extensions\n",
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "# Your already-initialized/trained model:\n",
    "# model = resnet50(pretrained=True, axx_mult=axx_mult)  # (or your own wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "373b8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): AdaPT_Conv2d_Systolic(\n",
       "    (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): AdaPT_Linear_Systolic(\n",
       "    (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adapt.approx_layers.systolic_utils import compare_exact_vs_approx, make_exact_and_approx_models\n",
    "from models.resnet_systolic import resnet50_systolic\n",
    "axx_mult=\"mul8s_acc\"\n",
    "model_exact,model_approx = make_exact_and_approx_models(model,  \n",
    "                    model_factory=lambda: resnet50(pretrained=True, axx_mult = axx_mult)\n",
    "                    , axx_mult=axx_mult)\n",
    "\n",
    "model_exact.eval()\n",
    "model_approx.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e4340a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.76232749699557\n",
      "Accuracy of the network on the 10000 test images: 93.5096 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "#model = resnet50(pretrained=False, axx_mult=axx_mult)\n",
    "#model.load_state_dict(torch.load(save_path))\n",
    "model_approx.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model_approx(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab298d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31cc614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.71960497600958\n",
      "Accuracy of the network on the 10000 test images: 93.5096 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "#model = resnet50(pretrained=False, axx_mult=axx_mult)\n",
    "#model.load_state_dict(torch.load(save_path))\n",
    "model_exact.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model_exact(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b732223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_1L2H/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): AdaPT_Conv2d_Systolic(\n",
       "    (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d_Systolic(\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): AdaPT_Conv2d_Systolic(\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): AdaPT_Linear_Systolic(\n",
       "    (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axx_mult=\"mul8s_1L2H\"\n",
    "model_exact,model_approx = make_exact_and_approx_models(model,  \n",
    "                    model_factory=lambda: resnet50(pretrained=True, axx_mult = axx_mult)\n",
    "                    , axx_mult=axx_mult)\n",
    "\n",
    "model_exact.eval()\n",
    "model_approx.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9778ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.8867325559986\n",
      "Accuracy of the network on the 10000 test images: 93.5096 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.77874595100002\n",
      "Accuracy of the network on the 10000 test images: 93.5096 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "#model = resnet50(pretrained=False, axx_mult=axx_mult)\n",
    "#model.load_state_dict(torch.load(save_path))\n",
    "model_exact.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model_exact(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the exact network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "#model = resnet50(pretrained=False, axx_mult=axx_mult)\n",
    "#model.load_state_dict(torch.load(save_path))\n",
    "model_approx.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model_approx(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the approx network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Evaluating exact systolic\n"
     ]
    }
   ],
   "source": [
    "axx_mult=\"mul8s_acc\"\n",
    "acc_baseline, acc_exact, acc_approx, delta = compare_exact_vs_approx(\n",
    "    model,\n",
    "    test_loader,\n",
    "    model_factory=lambda: resnet50(pretrained=False, axx_mult = axx_mult),\n",
    "    axx_mult=axx_mult,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "print(f\"Baseline: {acc_baseline:.4f} | Exact systolic: {acc_exact:.4f} | \"\n",
    "      f\"Approx systolic: {acc_approx:.4f} | ={delta:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb67da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "axx_mult = 'mul8s_1L2H'\n",
    "acc_baseline, acc_exact, acc_approx, delta = compare_exact_vs_approx(\n",
    "    model,\n",
    "    test_loader,\n",
    "    model_factory=lambda: resnet50(pretrained=True, axx_mult = axx_mult),\n",
    "    axx_mult=axx_mult,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "print(f\"Baseline: {acc_baseline:.4f} | Exact systolic: {acc_exact:.4f} | \"\n",
    "      f\"Approx systolic: {acc_approx:.4f} | ={delta:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d31425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb58a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
